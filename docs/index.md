---
marp: true
title: Нагружаем банки
description: Как ускорить запросы к InfluxDB с помощью InfluxQL Continuous Queries и разделения данных 
theme: vtb_tks
template: bespoke
paginate: true
_paginate: false

---

<!-- _class: lead12
-->

# Нагружаем банки<br>Смирнов Вячеслав<br>Рогожников Максим

## __Москва, 2021__

<!--

-->

---
<!-- _class: main
-->

# О технологиях и подходах реализации нагрузки в двух разных командах

<!-- 
Чуть более конкретные примеры.
Провести тестирование Heisenbug в Firefox. 
Максим, ваш выход ))

Не словами а конкретикой

2) Не очень понятно, что делать с записью?
Если запись не делать, 
то каждый может высказываться на любую тему.

Непотребство из записи будет убрано

Раписание - выйти в эфир в формате Главной студии, 
круглый стол по производительности
6 октября, начинается за 15 минут до конца доклада, 
30 минут перерыва
15 минут после начала следующего доклада
-->

---
<!-- _class: main -->

* Планирование
* Профиль нагрузки
* Инструменты
* Тестовый стенд
* Тестовые данные
* Тестирование на продуктиве
* Виды тестов
* CI/CD для нагрузки
* Мониторинг
* Логи
* Отчеты
* Кто делает запуски тестов
* Кто поддерживает тесты

---

<!-- _class: title-->

# Тестирую и ускоряю ДБО для юридических лиц в банке ВТБ
## __Развиваю @qa_load__

![bg cover](img/omsk.jpg)

<!-- 
Повышаю качество более десяти лет. Занимаюсь системой дистанционного банковского обслуживания юридических лиц. Основной профиль моей работы — тестирование производительности. Развиваю сообщество инженеров по тестированию производительности, помогая коллегам в telegram чате «QA — Load & Performance».

Занимаюсь оформлением дефектов и предварительными действиями для этого: профилированием JVM, оптимизаций SQL-запросов, разработкой досок в Grafana, группировкой логов в Kibana. Автоматизирую все, что сделал несколько раз.
Давно не писал скрипты, но поддерживаю навык за счет ответов на вопросы коллег.
Работаю в продуктовой команде. Но у нас в системе более 400-т сервисов. Из-за большого количества сервисов на поддержке наша продуктовая команда - сервисная, с большим беклогом, когда все надо сделать вчера

-->

---



<!-- _class: title_tks -->

# Тестирую и ускоряю системы в Тинькофф
## __Развиваю @qa_load__

![bg cover](img/Maks.jpg)

<!-- 
Я к сожалению или к счастью не занимаюсь заведением дефектов. Да, раньше я это тоже делал, но сейчас у нас чуть другой подход к НТ, я говорю у нас т.к. сложно делать НТ для ГК Тинькофф в одного, когда у тебя каждый день 100 релизов разных приложений как монолитных так и микросервисных. Поэтому мой подход заключается в том, чтобы дать инструменты командам, которые сами все сделают. Про это я и поведаю вам далее.
-->

---
<!-- _class: compare2
-->

- Регулярное НТ основных сервисов
- НТ прикладных сервисов не наше
- Знимаемся профилированием и оптимизацией всех сервисов
- Приоритетно занимаемся разбором обращений клиентов

1. Мы не всегда делаем НТ всего
1. Часто НТ делает команда сама
1. Делаем ревью скриптов и результатов
1. Приоритетно помогаем бизнес-критичным системам

<!--
# В чем отличия

Максим: Кто отвечает за НТ в принципе и какая у нас роль. Мы не всегда делаем НТ всего. Часто НТ делает команда сама, а мы лишь делаем ревью скриптов и их результаты. Да, у нас есть бизнес-линии как мы это называем или продукты например инвестиции, финансовые системы и т.д. на бизнес-критичных системах мы безусловно обращаем большее вниманием и помогаем им в приоритетном порядке.

Слава: У нас есть разделение на сервисы платформы и прикладные сервисы. Сервисы платформы наиболее нагруженные, делаем НТ сами. И помогаем командам с профилированием, пишем для команд дефекты, в которых указано в какой строке кода сервис тормозит.

# Что общего
Работаем  IT-компаниях, предоставляющие банковские услуги. Где пишут и оптимизируют свой же код. Работаем в командах нагрузки, в которых сосредоточена экспертиза по тестированию производительности. В сравнимых условиях и сравнимых командах, но очень разных.

-->



---
<!-- _class: main
-->

# Планирование

---
<!-- _class: head_tks
-->
# Канбан

## __Стандартные проекты НТ__

## __Поддержка и развитие инфраструктуры__

## __Разработка инструментов НТ__

Приоритетное направление

**_![ opacity:40% ](themes/img/tks2.png)_**

<!--
Максим: у нас канбан. Мы работаем как сервисная команда и как я говорил ранее кроме проектов НТ у нас есть свои проекты по разработке инструментов НТ и поддержки инфраструктуры вокруг них. По этому наши задачи разделены на 3 больших блока: стандартные проекты НТ, поддержка и развитие инфраструктуры и собственно разработка инструментов НТ. Приоритет у нас больше смещен в пользу последнего.
-->

---
<!-- class: head2 -->
# Скрам

## __Оформляем дефекты и задачи на команды,__
## __но не всё подтверждаем сами__
## __и не всё  в рамках спринта__
Так как исправления багов
приходят в течение спринта
## __Часто работаем по двое__
## __Контейнеры на задачи__


**_![ opacity:50%  ](img/team.svg)_**

<!--
Слава: у нас тоже был канбан, вытягивали. Теперь скрам - планируем. Но планируем с фактором неопределенности.

Заводим много дефектов и задач в беклоги других команд, и они возвращаются на нас с некотроллируемой скоростью, как срочные задачи, которые надо проверить в ближайшее время.

Стенда три, а инженеров больше 6-ти, и мы часто работаем по двое. Это увеличивает оценку задач.

Поэтому используем контейнеры на задачи, чтобы погасить фактор неопределенности. Например, 3 дня мы будем оптимизировать SQL-запросы. А какие именно, кто именно, пока не знаем.
-->
---
<!-- class: head2 -->
# Контейнеры на задачи

## __Разработка инструментов анализа__
Мониторинг, анализ, отчет
## __Поддержка инфраструктуры и стендов__
## __Регулярные тесты__

## __Профилирование__
## __Замеры__



**_![ opacity:80% ](img/container.jpg)_**


---
<!-- _class: compare
-->

- Сервисная команда проекта
- Скрам
- Разработка инструментов анализа
- Поддержка стендов
- Регулярные тесты
- Профилирование
- Замеры

1. Сервисная команда компании
1. Канбан
1. Разработка инструментов НТ
1. Поддержка инфраструктуры
1. Стандартные проекты НТ


---
<!-- _class: main
-->

# Профиль нагрузки

---

<!-- class: head2 -->

# Прогноз профиля, но точный SLA

## __Состав операций с легаси__ 

Но с учетом новых операций

## __Интенсивность с легаси__

Но с учетом прогноза роста

## __SLA c продуктива__

С ненагруженной системы



**_![ opacity:20%  ](themes/img/lead/lead04.png)_**

<!--
Слава: Пропорции продуктива с более высокой интенсивностью
На продуктиве есть механизм КПЭ (контрольных показателей эффективности), внутренняя аналитика. На ее основе строится соотношения в профиле нагрузки. Если известно, что карточка документа открывалась за неделю 10 000 раз, а сохранялась 9 000 раз, то мы знаем, что только 90% открытий приводит к сохранениям и учитываем пропорцию в профиле. А интенсивность увеличиваем до отказа, зная, что прошли 1 продуктив, 2 продуктива, ... 20 продуктивов.

Профиль получить и реализовать в скриптах несложно. Сложно получить и согласовать SLA. В качестве SLA используются продуктивные метрики КПЭ.


-->

---
<!-- _class: head_tks
-->
# Автосбор профиля по RED либо по логам

## __Соответствие профиля продуктиву__

Минимум на 95%

## __Соответствие интенсивности продуктиву__

На 100%

## __Требуем от команд SLA и NFR__

Без этого не начинаем

**_![ opacity:40% ](themes/img/tks2.png)_**

---
<!-- _class: compare2
-->

- Для системы в процессе миграции
- Прогноз профиля
- Соответствие профиля легаси
- Соответствие интенсивности легаси + прогноз роста интенсивности
- Посчитали SLA с продуктива
- Источник профиля: база данных

1. Для систем, которые уже в проде
1. Автосбор профиля
1. Соответствие профиля продуктиву
1. Соответствие интенсивности продуктиву
1. Требуем от команд SLA
1. Источник профиля: логи и ELK
1. RED: (Request) Rate, Errors, Duration
1. Источник RED: Prometheus + ELK


---
<!-- _class: main
-->

# Инструменты

---

# Maven, JMeter Maven Plugin, JMeter и его плагины

## __Работа по инцидентам: Skype + коллега__

Самые горячие проблемы 

## __Firefox/Chrome, Fiddler, JVM-профайлер__

Для проработки узких мест

## __Регулярные тесты: Apache.JMeter__

Для регресса

**_![ opacity:40%  ](themes/img/lead/lead04.png)_**

---
<!-- _footer: Источник фото: https://habr.com/ru/article/508466/
-->

# Работа по инцидентам: Skype + коллега

![ bg opacity:100%  ](img/show-me-bug.jpg)

---

# Firefox или Chrome

## __Developer Tools / Network__

![ bg   ](img/vtbbo.ru.png)

---

# Запросы к бекенду
## __Повторые запросы удалить__
## __Медленные профилировать__

![ bg   ](img/vtbbo.ru.1.png)

---
<!-- _class: head_tks
-->
# SBT, Gatling + свои плагины, Scala, K6, GoLang

## __Единообразный процесс запуска НТ__

## __Вне зависимости от инструмента__

## __Не важно что генерирует нагрузку__

Вы всегда получите
один и тот же результат 
и набор графиков

**_![ opacity:40% ](themes/img/tks.png)_**


---
<!-- _class: compare2
-->

- Maven, JMeter Maven Plugin, JMeter
- плагины JMeter
- Perfomance Center, Gatling
- Профиль нагрузки и SLA задается в property-файле
- Много профилирования и настройки

1. SBT, Gatling, Scala
1. свои плагины Gatling
1. K6, GoLang
1. Профиль нагрузки и SLA задается в yaml-файле
1. Единообразный процесс запуска НТ

---
<!-- _class: main
-->

# Тестовый стенд

---

# Фиксированные стенды, одно плечо продуктива

## __Три нагрузочных стенда__
Железо есть
Больше, чем на проде

## __Поддержка на нас__
У нас есть 4 стенда
Полноценных стенда
Справляемся с тремя

**_![ opacity:40%  ](themes/img/lead/lead04.png)_**

<!--
Слава: Фиксированные стенды, одно плечо продуктива
На стенды нагрузки выделено ресурсов столько же, сколько на продуктив. Но на продуктиве распределенный кластер на два плеча. А для нагрузки два отдельных стенда. 
Это позволяет проводить тестирование параллельно и на нагрузке выше продуктива.

Для локализации дефектов и проверки исправлений по ним используются третий небольшой стенды.

-->
---
<!-- _class: head_tks
-->
# Отдельные NS в k8s или переиспользуем стенд

## __Системы объединены по направлению__
И у них должны быть 
одинаковые потребности 
по ресурсам

## __Стараемся делать 1 плечо прода__

1 датацентр либо 
1 плечо нагрузки 

**_![ opacity:40% ](themes/img/tks.png)_**

<!--
Максим: чаще используем отдельные NS  в кубе или же контур в облаке openstack. Либо 1 стенд на несколько систем т.е. в 1 момент времени там залита лишь 1 система, а в другой другая. Системы объединены по направлению какому-то и у них должны быть одинаковые потребности по ресурсам. Стараемся делать 1 плечо прода - 1 датацентр либо 1 плечо нагрузки если есть балансер до. Почему так, у нас очень много систем и мы быстро растем и держать контур лайк-прод нам не очень удобно.
-->

---
<!-- _class: compare2
-->

- Хорошие стенды, 1 плечо прода
- Kubernetes
- Стационарные стенды
- Стационарные тестовые базы
- Поддерживаем стенды сами
- Jenkins, TeamCity, helm, kubectl

1. Хорошие стенды, 1 плечо прода
1. Kubernetes
1. Переиспользуемые стенды
1. Проливка обезличенных данных
1. Стенды поддерживают команды
1. Ansible, Terraform, Packer, Gitlab-CI и helm или kustomize чарты

<!--
Что общего
Тестовые стенды у нас хорошие. В банках редко бывают плохие тестовые стенды.

В чем отличия

Слава: Почему стенды фиксированные - тестовые данные очень сложно сохранить и восстановить, их слишком много. Даже если восстановить все БД полугодовой давности, то накат миграций на террабайтные базы данных будет длиться вечно. Поэтому миграции на базы данных накатываются регулярно и не откатываются, и стенды привязаны к базам данных.

Максим: Ansible, Terraform, Packer, Gitlab-CI и helm или kustomize чарты позволяют создать кластер на лету. Также у нас автоматизирован сбор снимков с продуктива и их обезличивание.

Получается:
фиксированные БД == фиксированные стенды
создаваемые по запросу БД == создаваемые по запросу стенды
И тестовые данные играют ключевую роль

-->


---
<!-- _class: head_tks
_footer: Источник фото: https://habr.com/ru/article/508466/
-->


![ bg opacity:100% height:100% ](img/yaml-developer.jpg)




---
<!-- _class: main
-->

# Тестовые данные

---

# Сгенерированные во время тестирования данные

## __Базы больше, чем на проде__
## __Минусы__
Диски заканчиваются
## __Плюсы__
Запросы завтрашнего дня
Медленные SQL-запросы


**_![ opacity:40%  ](themes/img/lead/lead04.png)_**

<!--
Слава: Сгенерированные во время тестирования
Хорошо бы тестировать на реальных данных, но это невозможно. Доступа до них просто нет. И чтобы знать производительность завтрашнего дня, надо иметь больше данных, чем на проде.

За счёт регулярных запусков тестов на стенде НТ много данных. И дисковое пространство наш самый критичный ресурс. 

Плюсы - есть возможность находить узкие места, раньше, чем на продуктиве. 
Минусы - можно услышать в ответ на дефект, что на продуктиве все быстро, хотя версия та же.

Фишка - данные не такие как на продуктиве. Их больше. И они не сентетические, они как настоящие.
-->

---
<!-- _class: head_tks
-->
# Клон БД с прода с обфусцированные данными

## __Сбор и обезличивание снимков прода__

## __Или сгенерированные данные__
Используем генераторы ФТ

## __Плюсы__
Данные, как на проде
По количеству и 
распределению


**_![ opacity:40% ](themes/img/tks.png)_**

<!--
Максим: Клон БД с прода с обфусцированные данными. Либо генерируем данные в пустой БД или в БД с уже существующими данными. У нас много генераторов данных для ФТ и АТ, мы можем использовать их.

Фишка - данные, такие как на продуктиве (по количеству и распределению).

-->

---
<!-- _class: compare2
-->

- Хорошие стенды, 1 плечо прода
- Kubernetes
- Стационарные стенды
- Стационарные тестовые базы
- Поддерживаем стенды сами
- Jenkins, TeamCity, helm, kubectl

1. Хорошие стенды, 1 плечо прода
1. Kubernetes
1. Переиспользуемые стенды
1. Проливка обезличенных данных
1. Стенды поддерживают команды
1. Ansible, Terraform, Packer, Gitlab-CI и helm или kustomize чарты


<!--
Что общего
Алгоритмы + структуры данных = программа
Никлаус Вирт

Стенд с сервисами + тестовые данные = нагрузочный стенд
Инженер НТ

Для тестов НТ данные необходимы. Так или иначе их надо иметь. Обфусцированные, генерирование, любые - они нужны. Да побольше, да побольше
В чем отличия

Максим: Так ведь если данные не такие как на продуктиве, то тест не настоящий!!!!
Надо делать как на продуктиве

Слава: Да, но если не делать данных больше, чем на продуктиве, то как же спрогнозировать нагрузку завтрашнего дня? И вообще, если обезличить данные, то ФИО из Смирнов Вячеслав и Семенов Степан превращается в Иван1 Иванов и Иван2 Иванов, статистика едет, связки ломаются, запросы становятся другими или вообще перестают работать: в одной таблице номер один, а в другой таблице номер другой и ничего не работает.

Если надо тестировать на продуктивных данных, то это без деперсонализации и сразу на продуктиве. Но мы так не делаем

-->
---
<!-- _class: main
-->

# Тестирование на продуктиве

---
<!-- _class: head_tks
-->
# Тестируем на проде то, что не списывает деньги

## __Нагрузка живым трафиком: 25%, 60%, 100%__

Настройкой балансера

## __Нагрузка синтетическими запросами__

Выведя ноду из ротации

**_![ opacity:40% ](themes/img/tks.png)_**

<!--
Максим: А мы так делаем. Ха, ха!!!

Не тестируется то, что списывает деньги, вроде.... Но сервисы, не списывающие деньги, можно нагрузить. Тестирование проводится вместе с командами, вместе с SRE в моменте. Подается нагрузка и оценивается, как система себя ведет. И нагрузка отключается, если что-то идет не так

Фишка в том, что можно проверить всю цепочку интеграций.

Мы также можем перенаправлять трафик. За счет балансировки нагрузки. Нагрузить одну станцию из 4-х не на 25% нагрузки, а на 60% или 100%, посмотреть, как она себя поведет под большей нагрузкой. Эта нагрузка, которая создается реальными клиентами, не нагрузочными тестами.

Также можно вывести ноду из ротации и нагрузить ее синтетической нагрузкой.

Максим: А почемы вы так не делаете?!

Слава: Так это же рискованно. Разве у вас ничего не ломалось при этом и все шло как надо?
-->

---
<!-- _class: head_tks
-->
# Нагрузка на прод отключается, если что-то не так

## __При превышении SLA__

## __1. Утилизация__
## __2. Время отклика__
## __3. APDEX__



**_![ opacity:40% ](themes/img/tks.png)_**

<!--
Максим: Нет, не ломалось. Мы не доводим нагрузку до 100%. 100% меряется по SLA: утилизация, время отклика и APDEX.

Если так не делать, не тестировать на проде. То сложно получить реальную нагрузку. И не получится протестировать всю систему.
-->


---

# Не тестируем на продуктиве

## __Делаем анализ SQL-запросов с прода__
Регулярно
## __Делаем профилирование JVM__
Очень редко
## __Разбираем инциденты__
Ручные замеры

**_![ opacity:40%  ](themes/img/lead/lead04.png)_**

<!--

Мы на продуктиве не тестируем.
Регулярно запрашиваем и анализируем статистику с прода. По SQL-запросам в частности. Иногда профилируем проблемные сервисы под живой нагрузкой.

-->

---
<!-- _class: compare
-->

- Не тестируем на продуктиве, наблюдаем, созерцаем
- Анализируем pg_stat_statements
- Профилируем JVM

1. Тестируем сервисы, которые не списывают деньги
1. Перенастройкой балансировщика
1. Синтетическим трафиком на выведенную из балансировки ноду
1. Прекращаем при превышении SLA
1. Утилизация, время отклика, APDEX

<!--
Слава: Все протестировать нельзя. За всеми графиками не уследить, получим просто Alert Storm. Можно протестировать все в рамках одного вида теста, контролируемого, более узкого

Максим: Да, но это зависит от вида теста
-->

---
<!-- _class: main
-->

# Виды тестов

---

# Интеграционные тесты на поиск максимума

## __Основные тесты — регрессионные__
Регулярно
## __Дополнительные тесты — замеры__
Chrome, Excel, Fiddler, Profiler
## __Подтверждение__
Каждый раз замедление

**_![ opacity:40%  ](themes/img/lead/lead04.png)_**

<!--
Слава: Интеграционные тесты на поиск максимума и подтверждение
Основные тесты - регрессионные.

Дополнительные тесты - просто сделать замеры в браузере. Спрофилировать и найти узкие места. А также такие же тесты но на больших объемах данных. Тоже просто в браузере. Эмуляция работы крупных клиентов. По вкладку в количество и качество дефектов, они такие же как регрессионные.

Третья группа тестов - уменьшенный регрессионный. На подтверждение исправления дефектов. Делается на небольшом стенде в четыре шага:
Эталонный тест
Установка обновления
Контрольный тест
Сравнение

-->
---
<!-- _class: head_tks
-->
# Нагрузка на прод отключается, если что-то не так

## __При превышении SLA__

## __1. Утилизация__
## __2. Время отклика__
## __3. APDEX__



**_![ opacity:40% ](themes/img/tks.png)_**

---
<!-- _class: main
-->

# CI/CD для нагрузки

---
<!-- _class: main
-->

# Мониторинг

---
<!-- _class: main
-->

# Логи

---
<!-- _class: main
-->

# Отчеты

---
<!-- _class: main
-->

# Кто делает запуски тестов

---
<!-- _class: main
-->

# Кто поддерживает тесты


---
<!-- _class: main
-->

# Итоги


---

<!-- _class: lead12
-->

# Вопросы/ответы<br> Нагружаем банки<br>ВТБ, Тинькофф

## __Вячеслав, Максим, @qa_load__



